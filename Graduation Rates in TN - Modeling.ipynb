{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./Data/scaled_grad_demo_fin.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grad_rate</th>\n",
       "      <th>ECONOMICALLY_DISADVANTAGED</th>\n",
       "      <th>H_Female</th>\n",
       "      <th>AA_FEMALE</th>\n",
       "      <th>W_FEMALE</th>\n",
       "      <th>AA_MALE</th>\n",
       "      <th>W_MALE</th>\n",
       "      <th>H_MALE</th>\n",
       "      <th>AA</th>\n",
       "      <th>H</th>\n",
       "      <th>W</th>\n",
       "      <th>Expend_per_pupil</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.647137</td>\n",
       "      <td>-0.340444</td>\n",
       "      <td>-0.810652</td>\n",
       "      <td>-0.749432</td>\n",
       "      <td>0.881421</td>\n",
       "      <td>-0.731183</td>\n",
       "      <td>0.939311</td>\n",
       "      <td>-1.003977</td>\n",
       "      <td>-0.743636</td>\n",
       "      <td>-0.922150</td>\n",
       "      <td>0.926043</td>\n",
       "      <td>-0.247486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.496101</td>\n",
       "      <td>0.295084</td>\n",
       "      <td>-0.742734</td>\n",
       "      <td>-0.610572</td>\n",
       "      <td>0.488740</td>\n",
       "      <td>-0.632984</td>\n",
       "      <td>0.972940</td>\n",
       "      <td>-0.629554</td>\n",
       "      <td>-0.624308</td>\n",
       "      <td>-0.691083</td>\n",
       "      <td>0.747043</td>\n",
       "      <td>-0.077559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.042992</td>\n",
       "      <td>-0.669709</td>\n",
       "      <td>0.225286</td>\n",
       "      <td>-0.220271</td>\n",
       "      <td>0.073510</td>\n",
       "      <td>-0.104159</td>\n",
       "      <td>-0.119980</td>\n",
       "      <td>0.183801</td>\n",
       "      <td>-0.163735</td>\n",
       "      <td>0.205828</td>\n",
       "      <td>-0.025222</td>\n",
       "      <td>1.379947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.949210</td>\n",
       "      <td>-0.714760</td>\n",
       "      <td>0.031734</td>\n",
       "      <td>-0.641120</td>\n",
       "      <td>0.294973</td>\n",
       "      <td>-0.573553</td>\n",
       "      <td>0.814632</td>\n",
       "      <td>-0.067018</td>\n",
       "      <td>-0.610439</td>\n",
       "      <td>-0.020230</td>\n",
       "      <td>0.568360</td>\n",
       "      <td>-0.278540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.410118</td>\n",
       "      <td>0.520390</td>\n",
       "      <td>3.856570</td>\n",
       "      <td>-0.095779</td>\n",
       "      <td>-0.799500</td>\n",
       "      <td>-0.123050</td>\n",
       "      <td>-0.743684</td>\n",
       "      <td>3.180804</td>\n",
       "      <td>-0.109695</td>\n",
       "      <td>3.541708</td>\n",
       "      <td>-0.784013</td>\n",
       "      <td>-1.092946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>0.345064</td>\n",
       "      <td>-0.340087</td>\n",
       "      <td>0.645130</td>\n",
       "      <td>-0.160112</td>\n",
       "      <td>-0.038207</td>\n",
       "      <td>-0.149754</td>\n",
       "      <td>-0.012516</td>\n",
       "      <td>0.629353</td>\n",
       "      <td>-0.155676</td>\n",
       "      <td>0.643992</td>\n",
       "      <td>-0.025573</td>\n",
       "      <td>-0.888277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>0.798174</td>\n",
       "      <td>-1.560176</td>\n",
       "      <td>-0.530941</td>\n",
       "      <td>-0.422304</td>\n",
       "      <td>0.470175</td>\n",
       "      <td>-0.385032</td>\n",
       "      <td>0.388020</td>\n",
       "      <td>-0.400242</td>\n",
       "      <td>-0.405676</td>\n",
       "      <td>-0.467638</td>\n",
       "      <td>0.435583</td>\n",
       "      <td>-1.044175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>0.647137</td>\n",
       "      <td>-0.768097</td>\n",
       "      <td>-0.901072</td>\n",
       "      <td>-0.606816</td>\n",
       "      <td>0.650322</td>\n",
       "      <td>-0.509172</td>\n",
       "      <td>0.773584</td>\n",
       "      <td>-0.499283</td>\n",
       "      <td>-0.561095</td>\n",
       "      <td>-0.698286</td>\n",
       "      <td>0.724858</td>\n",
       "      <td>0.325878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>0.798174</td>\n",
       "      <td>-1.298110</td>\n",
       "      <td>-0.259168</td>\n",
       "      <td>-0.374950</td>\n",
       "      <td>0.246499</td>\n",
       "      <td>-0.412574</td>\n",
       "      <td>0.458281</td>\n",
       "      <td>-0.167937</td>\n",
       "      <td>-0.395199</td>\n",
       "      <td>-0.213734</td>\n",
       "      <td>0.360024</td>\n",
       "      <td>-0.814397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>0.345064</td>\n",
       "      <td>-1.222298</td>\n",
       "      <td>-0.280149</td>\n",
       "      <td>-0.666933</td>\n",
       "      <td>1.839309</td>\n",
       "      <td>-0.683766</td>\n",
       "      <td>-0.484593</td>\n",
       "      <td>-0.701696</td>\n",
       "      <td>-0.678150</td>\n",
       "      <td>-0.506623</td>\n",
       "      <td>0.669462</td>\n",
       "      <td>4.997889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>267 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     grad_rate  ECONOMICALLY_DISADVANTAGED  H_Female  AA_FEMALE  W_FEMALE  \\\n",
       "0     0.647137                   -0.340444 -0.810652  -0.749432  0.881421   \n",
       "1     0.496101                    0.295084 -0.742734  -0.610572  0.488740   \n",
       "2     0.042992                   -0.669709  0.225286  -0.220271  0.073510   \n",
       "3     0.949210                   -0.714760  0.031734  -0.641120  0.294973   \n",
       "4    -0.410118                    0.520390  3.856570  -0.095779 -0.799500   \n",
       "..         ...                         ...       ...        ...       ...   \n",
       "262   0.345064                   -0.340087  0.645130  -0.160112 -0.038207   \n",
       "263   0.798174                   -1.560176 -0.530941  -0.422304  0.470175   \n",
       "264   0.647137                   -0.768097 -0.901072  -0.606816  0.650322   \n",
       "265   0.798174                   -1.298110 -0.259168  -0.374950  0.246499   \n",
       "266   0.345064                   -1.222298 -0.280149  -0.666933  1.839309   \n",
       "\n",
       "      AA_MALE    W_MALE    H_MALE        AA         H         W  \\\n",
       "0   -0.731183  0.939311 -1.003977 -0.743636 -0.922150  0.926043   \n",
       "1   -0.632984  0.972940 -0.629554 -0.624308 -0.691083  0.747043   \n",
       "2   -0.104159 -0.119980  0.183801 -0.163735  0.205828 -0.025222   \n",
       "3   -0.573553  0.814632 -0.067018 -0.610439 -0.020230  0.568360   \n",
       "4   -0.123050 -0.743684  3.180804 -0.109695  3.541708 -0.784013   \n",
       "..        ...       ...       ...       ...       ...       ...   \n",
       "262 -0.149754 -0.012516  0.629353 -0.155676  0.643992 -0.025573   \n",
       "263 -0.385032  0.388020 -0.400242 -0.405676 -0.467638  0.435583   \n",
       "264 -0.509172  0.773584 -0.499283 -0.561095 -0.698286  0.724858   \n",
       "265 -0.412574  0.458281 -0.167937 -0.395199 -0.213734  0.360024   \n",
       "266 -0.683766 -0.484593 -0.701696 -0.678150 -0.506623  0.669462   \n",
       "\n",
       "     Expend_per_pupil  \n",
       "0           -0.247486  \n",
       "1           -0.077559  \n",
       "2            1.379947  \n",
       "3           -0.278540  \n",
       "4           -1.092946  \n",
       "..                ...  \n",
       "262         -0.888277  \n",
       "263         -1.044175  \n",
       "264          0.325878  \n",
       "265         -0.814397  \n",
       "266          4.997889  \n",
       "\n",
       "[267 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=['grad_rate'])\n",
    "y = data[['grad_rate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25, random_state = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLR_model = LinearRegression()\n",
    "MLR_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5870716921652415"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLR_model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = MLR_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6034957271086209"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
