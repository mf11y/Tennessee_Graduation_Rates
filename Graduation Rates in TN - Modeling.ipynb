{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./Data/scaled_grad_demo_fin.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ECONOMICALLY_DISADVANTAGED</th>\n",
       "      <th>H_Female</th>\n",
       "      <th>AA_FEMALE</th>\n",
       "      <th>W_FEMALE</th>\n",
       "      <th>AA_MALE</th>\n",
       "      <th>W_MALE</th>\n",
       "      <th>H_MALE</th>\n",
       "      <th>AA</th>\n",
       "      <th>H</th>\n",
       "      <th>W</th>\n",
       "      <th>Expend_per_pupil</th>\n",
       "      <th>grad_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.340444</td>\n",
       "      <td>-0.810652</td>\n",
       "      <td>-0.749432</td>\n",
       "      <td>0.881421</td>\n",
       "      <td>-0.731183</td>\n",
       "      <td>0.939311</td>\n",
       "      <td>-1.003977</td>\n",
       "      <td>-0.743636</td>\n",
       "      <td>-0.922150</td>\n",
       "      <td>0.926043</td>\n",
       "      <td>-0.247486</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.295084</td>\n",
       "      <td>-0.742734</td>\n",
       "      <td>-0.610572</td>\n",
       "      <td>0.488740</td>\n",
       "      <td>-0.632984</td>\n",
       "      <td>0.972940</td>\n",
       "      <td>-0.629554</td>\n",
       "      <td>-0.624308</td>\n",
       "      <td>-0.691083</td>\n",
       "      <td>0.747043</td>\n",
       "      <td>-0.077559</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.669709</td>\n",
       "      <td>0.225286</td>\n",
       "      <td>-0.220271</td>\n",
       "      <td>0.073510</td>\n",
       "      <td>-0.104159</td>\n",
       "      <td>-0.119980</td>\n",
       "      <td>0.183801</td>\n",
       "      <td>-0.163735</td>\n",
       "      <td>0.205828</td>\n",
       "      <td>-0.025222</td>\n",
       "      <td>1.379947</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.714760</td>\n",
       "      <td>0.031734</td>\n",
       "      <td>-0.641120</td>\n",
       "      <td>0.294973</td>\n",
       "      <td>-0.573553</td>\n",
       "      <td>0.814632</td>\n",
       "      <td>-0.067018</td>\n",
       "      <td>-0.610439</td>\n",
       "      <td>-0.020230</td>\n",
       "      <td>0.568360</td>\n",
       "      <td>-0.278540</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.520390</td>\n",
       "      <td>3.856570</td>\n",
       "      <td>-0.095779</td>\n",
       "      <td>-0.799500</td>\n",
       "      <td>-0.123050</td>\n",
       "      <td>-0.743684</td>\n",
       "      <td>3.180804</td>\n",
       "      <td>-0.109695</td>\n",
       "      <td>3.541708</td>\n",
       "      <td>-0.784013</td>\n",
       "      <td>-1.092946</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>-0.340087</td>\n",
       "      <td>0.645130</td>\n",
       "      <td>-0.160112</td>\n",
       "      <td>-0.038207</td>\n",
       "      <td>-0.149754</td>\n",
       "      <td>-0.012516</td>\n",
       "      <td>0.629353</td>\n",
       "      <td>-0.155676</td>\n",
       "      <td>0.643992</td>\n",
       "      <td>-0.025573</td>\n",
       "      <td>-0.888277</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>-1.560176</td>\n",
       "      <td>-0.530941</td>\n",
       "      <td>-0.422304</td>\n",
       "      <td>0.470175</td>\n",
       "      <td>-0.385032</td>\n",
       "      <td>0.388020</td>\n",
       "      <td>-0.400242</td>\n",
       "      <td>-0.405676</td>\n",
       "      <td>-0.467638</td>\n",
       "      <td>0.435583</td>\n",
       "      <td>-1.044175</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>-0.768097</td>\n",
       "      <td>-0.901072</td>\n",
       "      <td>-0.606816</td>\n",
       "      <td>0.650322</td>\n",
       "      <td>-0.509172</td>\n",
       "      <td>0.773584</td>\n",
       "      <td>-0.499283</td>\n",
       "      <td>-0.561095</td>\n",
       "      <td>-0.698286</td>\n",
       "      <td>0.724858</td>\n",
       "      <td>0.325878</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>-1.298110</td>\n",
       "      <td>-0.259168</td>\n",
       "      <td>-0.374950</td>\n",
       "      <td>0.246499</td>\n",
       "      <td>-0.412574</td>\n",
       "      <td>0.458281</td>\n",
       "      <td>-0.167937</td>\n",
       "      <td>-0.395199</td>\n",
       "      <td>-0.213734</td>\n",
       "      <td>0.360024</td>\n",
       "      <td>-0.814397</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>-1.222298</td>\n",
       "      <td>-0.280149</td>\n",
       "      <td>-0.666933</td>\n",
       "      <td>1.839309</td>\n",
       "      <td>-0.683766</td>\n",
       "      <td>-0.484593</td>\n",
       "      <td>-0.701696</td>\n",
       "      <td>-0.678150</td>\n",
       "      <td>-0.506623</td>\n",
       "      <td>0.669462</td>\n",
       "      <td>4.997889</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>267 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ECONOMICALLY_DISADVANTAGED  H_Female  AA_FEMALE  W_FEMALE   AA_MALE  \\\n",
       "0                     -0.340444 -0.810652  -0.749432  0.881421 -0.731183   \n",
       "1                      0.295084 -0.742734  -0.610572  0.488740 -0.632984   \n",
       "2                     -0.669709  0.225286  -0.220271  0.073510 -0.104159   \n",
       "3                     -0.714760  0.031734  -0.641120  0.294973 -0.573553   \n",
       "4                      0.520390  3.856570  -0.095779 -0.799500 -0.123050   \n",
       "..                          ...       ...        ...       ...       ...   \n",
       "262                   -0.340087  0.645130  -0.160112 -0.038207 -0.149754   \n",
       "263                   -1.560176 -0.530941  -0.422304  0.470175 -0.385032   \n",
       "264                   -0.768097 -0.901072  -0.606816  0.650322 -0.509172   \n",
       "265                   -1.298110 -0.259168  -0.374950  0.246499 -0.412574   \n",
       "266                   -1.222298 -0.280149  -0.666933  1.839309 -0.683766   \n",
       "\n",
       "       W_MALE    H_MALE        AA         H         W  Expend_per_pupil  \\\n",
       "0    0.939311 -1.003977 -0.743636 -0.922150  0.926043         -0.247486   \n",
       "1    0.972940 -0.629554 -0.624308 -0.691083  0.747043         -0.077559   \n",
       "2   -0.119980  0.183801 -0.163735  0.205828 -0.025222          1.379947   \n",
       "3    0.814632 -0.067018 -0.610439 -0.020230  0.568360         -0.278540   \n",
       "4   -0.743684  3.180804 -0.109695  3.541708 -0.784013         -1.092946   \n",
       "..        ...       ...       ...       ...       ...               ...   \n",
       "262 -0.012516  0.629353 -0.155676  0.643992 -0.025573         -0.888277   \n",
       "263  0.388020 -0.400242 -0.405676 -0.467638  0.435583         -1.044175   \n",
       "264  0.773584 -0.499283 -0.561095 -0.698286  0.724858          0.325878   \n",
       "265  0.458281 -0.167937 -0.395199 -0.213734  0.360024         -0.814397   \n",
       "266 -0.484593 -0.701696 -0.678150 -0.506623  0.669462          4.997889   \n",
       "\n",
       "     grad_rate  \n",
       "0         0.96  \n",
       "1         0.95  \n",
       "2         0.92  \n",
       "3         0.98  \n",
       "4         0.89  \n",
       "..         ...  \n",
       "262       0.94  \n",
       "263       0.97  \n",
       "264       0.96  \n",
       "265       0.97  \n",
       "266       0.94  \n",
       "\n",
       "[267 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting into train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=['grad_rate'])\n",
    "y = data['grad_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25, random_state = 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary to store results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "evals = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Multiple Linear Regression (OLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean MAE: -3.36E-02\n"
     ]
    }
   ],
   "source": [
    "MLR_model = LinearRegression()\n",
    "scores= cross_val_score(MLR_model, X_train, y_train, cv=5, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "mean_mae = np.mean(scores)\n",
    "print(\"mean MAE: %.2E\" %(mean_mae))\n",
    "\n",
    "evals['MLR'] =  mean_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge without hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean MAE: -3.34E-02\n"
     ]
    }
   ],
   "source": [
    "Ridge_model = Ridge(alpha=1)\n",
    "scores= cross_val_score(Ridge_model, X_train, y_train, cv=5, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "mean_mae = np.mean(scores)\n",
    "print(\"mean MAE: %.2E\" %(mean_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge with hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: -3.21E-02\n",
      "Config: {'alpha': 49.900000000000006}\n"
     ]
    }
   ],
   "source": [
    "Ridge_model = Ridge()\n",
    "grid = dict()\n",
    "grid['alpha'] = np.arange(0,50,.1)\n",
    "search = GridSearchCV(Ridge_model, grid, scoring='neg_mean_absolute_error', cv=5, n_jobs=-1)\n",
    "results = search.fit(X_train, y_train)\n",
    "print('MAE: %.2E' % results.best_score_)\n",
    "print('Config: %s' % results.best_params_)\n",
    "\n",
    "evals['Ridge'] = [results.best_score_,results.best_params_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso without hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean MAE: -4.76E-02\n"
     ]
    }
   ],
   "source": [
    "lasso_model = Lasso(alpha=1)\n",
    "scores= cross_val_score(lasso_model, X, y, cv=5, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "mean_mae = np.mean(scores)\n",
    "print(\"mean MAE: %.2E\" %(mean_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Lasso with hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: -3.34E-02\n",
      "Config: {'alpha': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "lasso_model = Lasso()\n",
    "grid = dict()\n",
    "grid['alpha'] = np.arange(.0001,50,.1)\n",
    "search = GridSearchCV(lasso_model, grid, scoring='neg_mean_absolute_error', cv=5, n_jobs=-1)\n",
    "results = search.fit(X_train, y_train)\n",
    "print('MAE: %.2E' % results.best_score_)\n",
    "print('Config: %s' % results.best_params_)\n",
    "\n",
    "evals['Lasso'] = [results.best_score_,results.best_params_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest without hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean MAE: -3.38E-02\n"
     ]
    }
   ],
   "source": [
    "RF_model = RandomForestRegressor()\n",
    "scores= cross_val_score(RF_model, X_train, y_train, cv=5, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "mean_mae = np.mean(scores)\n",
    "print(\"mean MAE: %.2E\" %(mean_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest with hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: -3.37E-02\n",
      "Config: {'n_estimators': 400, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'auto', 'max_depth': 98, 'bootstrap': True}\n"
     ]
    }
   ],
   "source": [
    "RF_model = RandomForestRegressor()\n",
    "grid = {\n",
    "    'bootstrap': [True,False],\n",
    "    'max_depth': [int(x) for x in np.linspace(50, 110, num = 11)] + [None],\n",
    "    'max_features': ['auto', 'sqrt'],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'n_estimators': [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "}\n",
    "search = RandomizedSearchCV(RF_model, grid, n_iter=10,scoring='neg_mean_absolute_error', cv=5, n_jobs=-1)\n",
    "results = search.fit(X_train, y_train)\n",
    "print('MAE: %.2E' % results.best_score_)\n",
    "print('Config: %s' % results.best_params_)\n",
    "\n",
    "evals['RF'] = [results.best_score_,results.best_params_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MLR': -0.033626269121816973,\n",
       " 'Ridge': [-0.03210272912965349, {'alpha': 49.900000000000006}],\n",
       " 'Lasso': [-0.03338795966651996, {'alpha': 0.0001}],\n",
       " 'RF': [-0.03366485673843754,\n",
       "  {'n_estimators': 400,\n",
       "   'min_samples_split': 5,\n",
       "   'min_samples_leaf': 4,\n",
       "   'max_features': 'auto',\n",
       "   'max_depth': 98,\n",
       "   'bootstrap': True}]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge Regressor seems to be the best performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ridge_model = Ridge(alpha=evals['Ridge'][1]['alpha'])\n",
    "Ridge_model.fit(X_train, y_train)\n",
    "with open('./Model/Ridge_Regressor.pkl', 'wb') as f:\n",
    "    pickle.dump(Ridge_model, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
